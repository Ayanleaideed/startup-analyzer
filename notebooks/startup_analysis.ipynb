{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 11846,
     "status": "ok",
     "timestamp": 1735963394975,
     "user": {
      "displayName": "Ayanle Aideed",
      "userId": "01255363310038323227"
     },
     "user_tz": 360
    },
    "id": "Gf5NLErKBlGC",
    "outputId": "788ece8d-6bab-4e25-9df1-d6da921311f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydantic-ai\n",
      "  Downloading pydantic_ai-0.0.17-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.10.3)\n",
      "Collecting pydantic-ai-slim==0.0.17 (from pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai)\n",
      "  Downloading pydantic_ai_slim-0.0.17-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: eval-type-backport>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-ai-slim==0.0.17->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai) (0.2.0)\n",
      "Collecting griffe>=1.3.2 (from pydantic-ai-slim==0.0.17->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai)\n",
      "  Downloading griffe-1.5.4-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: httpx>=0.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic-ai-slim==0.0.17->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai) (0.28.1)\n",
      "Collecting logfire-api>=1.2.0 (from pydantic-ai-slim==0.0.17->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai)\n",
      "  Downloading logfire_api-2.11.1-py3-none-any.whl.metadata (972 bytes)\n",
      "Collecting mistralai>=1.2.5 (from pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai)\n",
      "  Downloading mistralai-1.2.5-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting anthropic>=0.40.0 (from pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai)\n",
      "  Downloading anthropic-0.42.0-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: openai>=1.54.3 in /usr/local/lib/python3.10/dist-packages (from pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai) (1.57.4)\n",
      "Collecting groq>=0.12.0 (from pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai)\n",
      "  Downloading groq-0.13.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting google-auth>=2.36.0 (from pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai)\n",
      "  Downloading google_auth-2.37.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: requests>=2.32.3 in /usr/local/lib/python3.10/dist-packages (from pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic>=0.40.0->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from anthropic>=0.40.0->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from anthropic>=0.40.0->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic>=0.40.0->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.36.0->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.36.0->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.36.0->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai) (4.9)\n",
      "Collecting colorama>=0.4 (from griffe>=1.3.2->pydantic-ai-slim==0.0.17->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.2->pydantic-ai-slim==0.0.17->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.2->pydantic-ai-slim==0.0.17->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.2->pydantic-ai-slim==0.0.17->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.2->pydantic-ai-slim==0.0.17->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai) (0.14.0)\n",
      "Collecting httpx>=0.27.2 (from pydantic-ai-slim==0.0.17->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jsonpath-python<2.0.0,>=1.0.6 (from mistralai>=1.2.5->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai)\n",
      "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from mistralai>=1.2.5->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai) (2.8.2)\n",
      "Collecting typing-inspect<0.10.0,>=0.9.0 (from mistralai>=1.2.5->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.54.3->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.3->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.3->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai) (2.2.3)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic>=0.40.0->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai) (1.2.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.36.0->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.8.2->mistralai>=1.2.5->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai) (1.17.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<0.10.0,>=0.9.0->mistralai>=1.2.5->pydantic-ai-slim[anthropic,groq,mistral,openai,vertexai]==0.0.17->pydantic-ai)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading pydantic_ai-0.0.17-py3-none-any.whl (9.7 kB)\n",
      "Downloading pydantic_ai_slim-0.0.17-py3-none-any.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading anthropic-0.42.0-py3-none-any.whl (203 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.37.0-py2.py3-none-any.whl (209 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading griffe-1.5.4-py3-none-any.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.1/128.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading groq-0.13.1-py3-none-any.whl (109 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.1/109.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading logfire_api-2.11.1-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mistralai-1.2.5-py3-none-any.whl (260 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.0/260.0 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, logfire-api, jsonpath-python, colorama, typing-inspect, httpx, griffe, google-auth, pydantic-ai-slim, mistralai, groq, anthropic, pydantic-ai\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.28.1\n",
      "    Uninstalling httpx-0.28.1:\n",
      "      Successfully uninstalled httpx-0.28.1\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 2.27.0\n",
      "    Uninstalling google-auth-2.27.0:\n",
      "      Successfully uninstalled google-auth-2.27.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires google-auth==2.27.0, but you have google-auth 2.37.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed anthropic-0.42.0 colorama-0.4.6 google-auth-2.37.0 griffe-1.5.4 groq-0.13.1 httpx-0.27.2 jsonpath-python-1.0.6 logfire-api-2.11.1 mistralai-1.2.5 mypy-extensions-1.0.0 pydantic-ai-0.0.17 pydantic-ai-slim-0.0.17 typing-inspect-0.9.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "5fa46eb6654e401fa083066131021e50",
       "pip_warning": {
        "packages": [
         "google"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Author: Ayanle A\n",
    "# Date: 01/02/2025\n",
    "# Description: This is a simple script that installs the required packages for the project\n",
    "%pip install pydantic-ai pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hIgJYoQBBqz1"
   },
   "outputs": [],
   "source": [
    "# Importing the required packages\n",
    "from pydantic_ai import Agent, messages\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any, Union\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "import asyncio\n",
    "import os\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sdIKpZXeCBqC"
   },
   "outputs": [],
   "source": [
    "# Setting the API keys and environment variables\n",
    "from google.colab import userdata\n",
    "os.environ[\"GEMINI_API_KEY\"]=userdata.get('GOOGLE_API_KEY')\n",
    "os.environ[\"OPENAI_API_KEY\"]=userdata.get('OPENAI_API_KEY').strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "avRigO77CSAX"
   },
   "outputs": [],
   "source": [
    "# Defining the model response\n",
    "class ResponseStatus(str, Enum):\n",
    "    APPROVED = \"approved\"\n",
    "    REJECTED = \"rejected\"\n",
    "    NEEDS_REVISION = \"needs_revision\"\n",
    "    REQUIRES_DISCUSSION = \"requires_discussion\"\n",
    "# Defining the concern\n",
    "class Concern(BaseModel):\n",
    "    topic: str\n",
    "    severity: str\n",
    "    impact_area: str\n",
    "    proposed_solution: str\n",
    "# Defining the model response\n",
    "class ModelResponse(BaseModel):\n",
    "    reason: str\n",
    "    response: ResponseStatus\n",
    "    confidence_score: float = Field(..., ge=0, le=1)\n",
    "    key_points: List[str] = Field(default_factory=list)\n",
    "    concerns: List[Concern] = Field(default_factory=list)\n",
    "    questions: List[str] = Field(default_factory=list)\n",
    "# Defining the model response decision\n",
    "class ModelResponseDecision(BaseModel):\n",
    "    reason: str\n",
    "    response: str = Field(..., max_length=10, description=\"Approved or rejectd\")\n",
    "    confidence_score: float = Field(..., ge=0, le=1)\n",
    "    key_points: List[str] = Field(default_factory=list)\n",
    "    concerns: List[Concern] = Field(default_factory=list)\n",
    "    questions: List[str] = Field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bNAysxi3hqHP"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initialize Agents\n",
    "LLM_MODEL = \"gemini-2.0-flash-exp\"\n",
    "LLM_MODEL_thinking_model = \"gemini-2.0-flash-thinking-exp\"\n",
    "LLM_MODEL_OPENAI = \"openai:gpt-4o-mini\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NasQ5jNuBzhN"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Startup Idea Agent (Idea Generation) \n",
    "# Initial agents \n",
    "# Market Analysis Agent\n",
    "market_agent = Agent(\n",
    "    model=LLM_MODEL,\n",
    "    result_type=ModelResponse,\n",
    "    retries=3,\n",
    "    system_prompt=\"\"\"You are a Market Research Expert. Analyze:\n",
    "        - Market size and growth potential\n",
    "        - Target audience demographics\n",
    "        - Market trends and competition\n",
    "        - Entry barriers and opportunities\n",
    "        Provide detailed market insights and potential challenges.\"\"\"\n",
    ")\n",
    "\n",
    "# Technical Feasibility Agent\n",
    "tech_agent = Agent(\n",
    "    model=LLM_MODEL,\n",
    "    result_type=ModelResponse,\n",
    "    retries=3,\n",
    "    system_prompt=\"\"\"You are a Technical Feasibility Expert. Evaluate:\n",
    "        - Technical complexity and requirements\n",
    "        - Development timeline and resources needed\n",
    "        - Scalability and maintenance considerations\n",
    "        - Technology stack recommendations\n",
    "        Focus on technical viability and implementation challenges.\"\"\"\n",
    ")\n",
    "\n",
    "# Financial Analysis Agent\n",
    "finance_agent = Agent(\n",
    "    model=LLM_MODEL,\n",
    "    result_type=ModelResponse,\n",
    "    retries=3,\n",
    "    system_prompt=\"\"\"You are a Financial Analysis Expert. Analyze:\n",
    "        - Initial investment requirements\n",
    "        - Revenue potential and business model\n",
    "        - Operating costs and margins\n",
    "        - Break-even analysis and ROI projections\n",
    "        Provide detailed financial insights and recommendations.\"\"\"\n",
    ")\n",
    "\n",
    "# Legal Compliance Agent\n",
    "legal_agent = Agent(\n",
    "    model=LLM_MODEL,\n",
    "    result_type=ModelResponse,\n",
    "    retries=3,\n",
    "    system_prompt=\"\"\"You are a Legal Compliance Expert. Evaluate:\n",
    "        - Regulatory requirements and compliance needs\n",
    "        - Intellectual property considerations\n",
    "        - Privacy and data protection implications\n",
    "        - Potential legal risks and mitigation strategies\n",
    "        Focus on legal viability and compliance requirements.\"\"\"\n",
    ")\n",
    "\n",
    "# Final Decision Maker Agent (Decision Making)\n",
    "decision_agent = Agent(\n",
    "    model=LLM_MODEL_OPENAI,\n",
    "    # Using OpenAI model for decision-making\n",
    "    result_type=ModelResponseDecision,\n",
    "    retries=3,\n",
    "    system_prompt=\"\"\"You are the Chief Decision Officer. Your role is to:\n",
    "        1. Synthesize insights from all expert agents.\n",
    "        2. Evaluate the overall viability of the startup idea, considering all relevant factors.\n",
    "        3. Provide a final decision: either 'PROVE' (approve) or 'REJECT' (deny).\n",
    "        4. Include a confidence score for your decision (from 0 to 100%).\n",
    "        5. Outline key action items and next steps based on your decision.\n",
    "        6. Consider all aspects—market potential, feasibility, scalability, financial projections, and any other relevant information.\n",
    "        7. Your decision should be balanced and thorough, ensuring the long-term success and sustainability of the idea.\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "blrrN1tZiNbG"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Run Initial Analysis \n",
    "# function to run initial analysis with all expert agents in parallel\n",
    "\n",
    "async def run_initial_analysis(idea_details: Dict[str, Any]) -> List[ModelResponse]:\n",
    "    \"\"\"Run initial analysis with all expert agents in parallel.\"\"\"\n",
    "    tasks = [\n",
    "        market_agent.run(f\"Analyze market potential for: {str(idea_details)}\"),\n",
    "        tech_agent.run(f\"Evaluate technical feasibility of: {str(idea_details)}\"),\n",
    "        finance_agent.run(f\"Analyze financial viability of: {str(idea_details)}\"),\n",
    "        legal_agent.run(f\"Assess legal implications of: {str(idea_details)}\")\n",
    "    ]\n",
    "    return await asyncio.gather(*tasks)\n",
    "# Display Expert Assessment \n",
    "def display_expert_assessment(agent_type: str, response: ModelResponse) -> None:\n",
    "    \"\"\"Display the assessment results from an expert agent.\"\"\"\n",
    "    print(f\"\\n{agent_type.title()} Expert Assessment:\")\n",
    "    print(f\"Recommendation: {response.data.response}\")\n",
    "    print(f\"Confidence: {response.data.confidence_score}\")\n",
    "    print(f\"Key Points: {', '.join(response.data.key_points)}\")\n",
    "    print(f\"Reasoning: {response.data.reason}\")\n",
    "# Run Cross-Analysis \n",
    "async def run_cross_analysis(context: str) -> Dict[str, ModelResponse]:\n",
    "    \"\"\"Run cross-analysis with all agents reviewing other experts' assessments.\"\"\"\n",
    "    cross_analysis_results = {}\n",
    "    agents = {\n",
    "        \"market\": market_agent,\n",
    "        \"technical\": tech_agent,\n",
    "        \"financial\": finance_agent,\n",
    "        \"legal\": legal_agent\n",
    "    }\n",
    "    # Run cross-analysis for each agent (like a peer review process)\n",
    "    for agent_type, agent in agents.items():\n",
    "        response = await agent.run(\n",
    "            f\"Review other experts' assessments and provide additional insights:\\n{context}\"\n",
    "        )\n",
    "        cross_analysis_results[agent_type] = response\n",
    "        display_expert_assessment(f\"{agent_type} Cross-Analysis\", response)\n",
    "    # Return the cross-analysis results\n",
    "    return cross_analysis_results\n",
    "# Display Final Decision \n",
    "def display_final_decision(decision: ModelResponse, finel_dic=False) -> None:\n",
    "    \"\"\"Display the final decision results.\"\"\"\n",
    "    if finel_dic:\n",
    "        print(f\"\\nFinal Decision:\")\n",
    "        print(f\"Recommendation: {decision.data.response}\")\n",
    "        print(f\"Reasoning: {decision.data.reason}\")\n",
    "        print(f\"Key Points: {', '.join(decision.data.key_points)}\")\n",
    "        print(f\"Decision: {decision.data.response}\")\n",
    "    else:\n",
    "      print(\"\\nFinal Decision:\")\n",
    "      print(f\"Recommendation: {decision.data.response}\")\n",
    "      print(f\"Confidence Score: {decision.data.confidence_score}\")\n",
    "      print(f\"Key Points: {', '.join(decision.data.key_points)}\")\n",
    "      print(f\"Reasoning: {decision.data.reason}\")\n",
    "# Evaluate Startup Idea \n",
    "async def evaluate_startup_idea(idea_details: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Main function to evaluate a startup idea through multiple rounds of expert analysis.\"\"\"\n",
    "    results = {}\n",
    "    context = []\n",
    "\n",
    "    # Stage 1: Initial Analysis\n",
    "    print(\"\\n=== Stage 1: Expert Analysis ===\")\n",
    "    initial_responses = await run_initial_analysis(idea_details)\n",
    "\n",
    "    for agent_type, response in zip(\n",
    "        [\"market\", \"technical\", \"financial\", \"legal\"],\n",
    "        initial_responses\n",
    "    ):\n",
    "        results[agent_type] = response.data\n",
    "        context.append(f\"{agent_type.title()} Analysis: {response.data.reason}\")\n",
    "        display_expert_assessment(agent_type, response)\n",
    "\n",
    "    # Stage 2: Cross-Analysis\n",
    "    print(\"\\n=== Stage 2: Cross-Analysis Discussion ===\")\n",
    "    cross_analysis_context = \"\\n\".join(context)\n",
    "    cross_analysis_results = await run_cross_analysis(cross_analysis_context)\n",
    "\n",
    "    for agent_type, response in cross_analysis_results.items():\n",
    "        results[f\"{agent_type}_cross_analysis\"] = response.data\n",
    "        context.append(f\"{agent_type.title()} Cross-Analysis: {response.data.reason}\")\n",
    "\n",
    "    # Stage 3: Final Decision\n",
    "    print(\"\\n=== Stage 3: Final Decision ===\")\n",
    "    final_context = \"\\n\".join(context)\n",
    "    final_decision = await decision_agent.run(\n",
    "        f\"Provide final decision based on all analyses:\\n{final_context}\"\n",
    "    )\n",
    "\n",
    "    results[\"final_decision\"] = final_decision.data\n",
    "    display_final_decision(final_decision, True)\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54981,
     "status": "ok",
     "timestamp": 1735968357716,
     "user": {
      "displayName": "Ayanle Aideed",
      "userId": "01255363310038323227"
     },
     "user_tz": 360
    },
    "id": "jfN4e1d_B4-Z",
    "outputId": "c58432ef-ac77-49be-e28f-85318cc52326"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Stage 1: Expert Analysis ===\n",
      "\n",
      "Market Expert Assessment:\n",
      "Recommendation: needs_revision\n",
      "Confidence: 0.8\n",
      "Key Points: Large market of health-conscious individuals aged 30-60 with increasing interest in digital health solutions., Non-invasive monitoring using smartphone sensors provides a competitive advantage., B2C subscription and B2B partnerships model offers diverse revenue streams.\n",
      "Reasoning: The AI-Powered Health Monitoring Platform has strong market potential but faces challenges. The market for digital health is growing, but competition is also intense. Success depends on user adoption, data privacy, and partnerships.\n",
      "\n",
      "Technical Expert Assessment:\n",
      "Recommendation: needs_revision\n",
      "Confidence: 0.7\n",
      "Key Points: Feasibility hinges on accurate sensor data and ML predictions., HIPAA compliance is mandatory and complex., Scalability of cloud infrastructure is essential., 12-month timeline may be aggressive; consider a phased approach., Initial investment might be insufficient; detailed cost analysis is needed.\n",
      "Reasoning: The project is feasible but requires careful planning and execution, particularly in the areas of data privacy and AI model accuracy.\n",
      "\n",
      "Financial Expert Assessment:\n",
      "Recommendation: needs_revision\n",
      "Confidence: 0.8\n",
      "Key Points: Initial investment of $500,000 is required., The revenue model includes B2C subscriptions and B2B partnerships., The platform leverages AI/ML and smartphone sensors., A development time of 12 months is estimated., Non-invasive monitoring using existing smartphone sensors is a key competitive advantage., HIPAA compliance is a critical requirement for handling health data., Cloud infrastructure is needed to support the platform., Target market is health-conscious individuals aged 30-60., The financial analysis is currently preliminary and requires more detailed assumptions and projections., Detailed cost breakdowns are required to estimate operating costs and margins\n",
      "Reasoning: The provided information allows for a preliminary assessment of the financial viability of the AI-Powered Health Monitoring Platform. However, a more detailed analysis would require additional data and assumptions.\n",
      "\n",
      "Legal Expert Assessment:\n",
      "Recommendation: needs_revision\n",
      "Confidence: 0.9\n",
      "Key Points: HIPAA compliance is critical., IP protection for algorithms and tech is essential., Data security must be prioritized., Clear partnership agreements are needed., User consent and transparency are key., Liability for inaccurate predictions needs to be addressed\n",
      "Reasoning: The AI-Powered Health Monitoring Platform has several legal and compliance considerations that need to be addressed for its viability. The use of health data, AI, and partnerships with healthcare providers requires a careful approach to ensure compliance with regulations and protect user privacy.\n",
      "\n",
      "=== Stage 2: Cross-Analysis Discussion ===\n",
      "\n",
      "Market Cross-Analysis Expert Assessment:\n",
      "Recommendation: approved\n",
      "Confidence: 0.8\n",
      "Key Points: Strong market potential in digital health but high competition., Success hinges on user adoption, data privacy, and strategic partnerships., Feasibility requires careful planning, especially in data privacy and AI model accuracy., Detailed financial analysis is needed., Legal and compliance considerations, especially regarding user data and AI, are critical.\n",
      "Reasoning: The market analysis is well-structured and identifies the key areas of concern. The need for user adoption, data privacy and strategic partnerships are accurately highlighted as crucial for the success of this product. The technical, financial, and legal analyses are appropriate and contribute to a comprehensive overview of the project.\n",
      "\n",
      "Technical Cross-Analysis Expert Assessment:\n",
      "Recommendation: needs_revision\n",
      "Confidence: 0.8\n",
      "Key Points: The technical analysis indicates feasibility but with key areas needing attention., Data privacy and AI model accuracy are critical technical challenges., Scalability should be considered for future growth.\n",
      "Reasoning: The project has potential but requires careful planning and execution, especially in data privacy, AI model accuracy, and regulatory compliance. Addressing these concerns is crucial for the project's technical viability.\n",
      "\n",
      "Financial Cross-Analysis Expert Assessment:\n",
      "Recommendation: needs_revision\n",
      "Confidence: 0.8\n",
      "Key Points: Market is competitive but with potential, Technical feasibility exists with careful planning, Financial assessment requires more data, Legal and compliance issues are significant\n",
      "Reasoning: The AI-Powered Health Monitoring Platform shows promise but has several areas of concern that need to be addressed. The market has potential, but it's competitive. Technical feasibility is present, but with caveats around data privacy and AI accuracy. Financials are still preliminary. Legal and compliance issues are significant. A more detailed analysis is needed before a final decision can be made.\n",
      "\n",
      "Legal Cross-Analysis Expert Assessment:\n",
      "Recommendation: needs_revision\n",
      "Confidence: 0.9\n",
      "Key Points: Legal compliance is crucial for the project's viability., Data privacy and security must be prioritized., Intellectual property protection is necessary., Risk management is essential to address potential liabilities., Further legal review and expert counsel are needed\n",
      "Reasoning: The AI-Powered Health Monitoring Platform presents significant legal and compliance considerations. The use of health data, AI, and partnerships with healthcare providers requires a careful approach to ensure compliance with regulations and protect user privacy. The legal analysis indicates that the project's viability hinges on addressing these issues effectively. The market, technical, and financial analyses all highlight potential challenges and areas requiring further consideration, but the legal concerns are particularly critical for the project's overall success and should be prioritized.\n",
      "\n",
      "=== Stage 3: Final Decision ===\n",
      "\n",
      "Final Decision:\n",
      "Recommendation: REJECT\n",
      "Reasoning: The AI-Powered Health Monitoring Platform presents a compelling market opportunity but is hindered by intense competition, significant legal and compliance challenges, and the necessity for a well-thought-out strategy to address user adoption and data privacy. While the technical feasibility exists, the concerns around AI accuracy and the need for detailed financial analysis raise red flags. Therefore, further research and development are essential before proceeding.\n",
      "Key Points: Strong market potential but intense competition, Significant legal and compliance challenges, Technical feasibility with caveats around AI model accuracy, Preliminary financial analysis insufficient for decision, User adoption and data privacy are critical factors\n",
      "Decision: REJECT\n"
     ]
    }
   ],
   "source": [
    "#  Example usage\n",
    "idea_details_1 = {\n",
    "    \"name\": \"AI-Powered Health Monitoring Platform\",\n",
    "    \"description\": \"Mobile app that uses smartphone sensors and ML to monitor vital signs and predict health issues\",\n",
    "    \"target_market\": \"Health-conscious individuals aged 30-60\",\n",
    "    \"revenue_model\": \"B2C subscription with B2B healthcare provider partnerships\",\n",
    "    \"technical_requirements\": [\"ML/AI development\", \"Mobile sensors integration\", \"HIPAA compliance\", \"Cloud infrastructure\"],\n",
    "    \"estimated_development_time\": \"12 months\",\n",
    "    \"initial_investment_needed\": \"$500,000\",\n",
    "    \"competitive_advantage\": \"Non-invasive monitoring using existing smartphone sensors\"\n",
    "}\n",
    "# Second idea\n",
    "idea_details_2 = {\n",
    "        \"name\": \"EcoTech Solutions\",\n",
    "        \"description\": \"Sustainable energy monitoring platform for homes\",\n",
    "        \"target_market\": \"Homeowners and property managers\",\n",
    "        \"technology\": \"IoT sensors, cloud platform, mobile app\",\n",
    "        \"business_model\": \"SaaS with hardware subscription\"\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "async def main():\n",
    "    # idea_details_1 or idea_details_2\n",
    "    results = await evaluate_startup_idea(idea_details_1)\n",
    "    return results\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNEIOJOapKEBt97wTuCSnOw",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
